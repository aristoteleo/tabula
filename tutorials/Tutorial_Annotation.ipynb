{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning on Pre-trained Tabula for Cell Type Annotation\n",
    "In this tutorial, we illustrate the finetuning steps for the downstream task cell type annotation.\n",
    "\n",
    "Here we takes Pancreas dataset as an example. Please refer to our manuscript for more information regarding the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import wandb\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "from tabula import logger\n",
    "from tabula.finetune.dataloader import CellAnnotationDataset\n",
    "from tabula.finetune.setup.annotation import CellTypeAnnotation\n",
    "from tabula.finetune.preprocessor import check_vocab, Preprocessor, get_pretrained_model\n",
    "from tabula.finetune.utils import FinetuneConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-define parameters \n",
    "- For detailed finetuning parameters, please refer to and modify the yaml file in ```params['config_path']```\n",
    "- For model weight, please download from this link: https://drive.google.com/drive/folders/19uG3hmvBZr2Zr4mWgIU-8SQ1dSg8GZuJ?usp=sharing\n",
    "- For ```data_params['finetune_data_path']``` and ```data_params['test_data_path']```, please download the zip file curated by scGPT from this link: https://drive.google.com/drive/folders/1biD__KaE_fhNry7U3d9XkCMRvtpa3xw5?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'seed': 23,\n",
    "    'config_path': '../resource/finetune_framework_annotation.yaml',\n",
    "    'save_folder': 'finetune_out/annotation_pancreas_test',\n",
    "    'model_path': '../weight/pancreas.pth',\n",
    "    'device': 'cuda:0',  # 'cuda:0' or 'cpu'\n",
    "}\n",
    "\n",
    "data_params = {\n",
    "    'finetune_data_path': '../data/annotation/pancreas/demo_train.h5ad',\n",
    "    'test_data_path': '../data/annotation/pancreas/demo_test.h5ad',\n",
    "    'vocab_path': '../resource/vocab.json',\n",
    "    'n_bins': 51,\n",
    "    'n_hvg': False,\n",
    "    'data_is_raw': False,\n",
    "    'batch_size': 32,\n",
    "    'n_workers': 4,\n",
    "}\n",
    "\n",
    "if_wandb = True\n",
    "wandb_params = {\n",
    "    'key': '644b123473f38af040ef215020d8e45acdf48fda',\n",
    "    'project': 'Annotation_tutorial_test',\n",
    "    'entity': 'sctab-downstream',\n",
    "    'task': 'annotation_pancreas_test'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Configuration loaded from ../resource/finetune_framework_annotation.yaml, save finetuning result to finetune_out/annotation_pancreas_test\n"
     ]
    }
   ],
   "source": [
    "seed_everything(params['seed'])\n",
    "os.makedirs(params['save_folder'], exist_ok=True)\n",
    "finetune_config = FinetuneConfig(seed=params['seed'], config_path=params['config_path'])\n",
    "\n",
    "finetune_config.set_finetune_param('enable_wandb', if_wandb)\n",
    "\n",
    "finetune_config.set_finetune_param('save_folder', params['save_folder'])\n",
    "logger.info(f'Configuration loaded from {params[\"config_path\"]}, save finetuning result to {params[\"save_folder\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjianhuilin2001\u001b[0m (\u001b[33msctab-downstream\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /mnt/first19T/linjh/.netrc\n",
      "/mnt/first19T/linjh/anaconda3/envs/sctabular/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/first19T/linjh/program/submission/shiyu/reverse_perturb/tabula/tutorials/wandb/run-20250303_200236-gbpwclc4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sctab-downstream/Annotation_tutorial_test/runs/gbpwclc4' target=\"_blank\">annotation_pancreas_test</a></strong> to <a href='https://wandb.ai/sctab-downstream/Annotation_tutorial_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sctab-downstream/Annotation_tutorial_test' target=\"_blank\">https://wandb.ai/sctab-downstream/Annotation_tutorial_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sctab-downstream/Annotation_tutorial_test/runs/gbpwclc4' target=\"_blank\">https://wandb.ai/sctab-downstream/Annotation_tutorial_test/runs/gbpwclc4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Wandb logging enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/first19T/linjh/anaconda3/envs/sctabular/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "if if_wandb:\n",
    "    wandb.login(key=wandb_params['key'])\n",
    "    wandb.init(project=wandb_params['project'], entity=wandb_params['entity'], name=wandb_params['task'])\n",
    "    wandb_logger = WandbLogger(project=wandb_params['project'], log_model=False, offline=False)\n",
    "    logger.info(f'Wandb logging enabled')\n",
    "else:\n",
    "    wandb_logger = None\n",
    "    logger.info(f'Wandb logging disabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/first19T/linjh/anaconda3/envs/sctabular/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/mnt/first19T/linjh/anaconda3/envs/sctabular/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Finetune data cell type: ['acinar', 'delta', 'beta', 'PSC', 'alpha', ..., 'endothelial', 'macrophage', 'schwann', 'mast', 't_cell']\n",
      "Length: 13\n",
      "Categories (13, object): ['PP', 'PSC', 'acinar', 'alpha', ..., 'macrophage', 'mast', 'schwann', 't_cell'] -- 13 types\n",
      "Tabula - INFO - Test data cell type: ['beta', 'PSC', 'ductal', 'alpha', 'acinar', ..., 'PP', 'MHC class II', 'endothelial', 'epsilon', 'mast']\n",
      "Length: 11\n",
      "Categories (11, object): ['MHC class II', 'PP', 'PSC', 'acinar', ..., 'ductal', 'endothelial', 'epsilon', 'mast'] -- 11 types\n"
     ]
    }
   ],
   "source": [
    "# load evaluation dataset as query set\n",
    "test_adata = sc.read(data_params['test_data_path'])\n",
    "# load finetune dataset as reference set\n",
    "finetune_adata = sc.read(data_params['finetune_data_path'])\n",
    "\n",
    "logger.info(f'Finetune data cell type: {finetune_adata.obs[\"Celltype\"].unique()} -- {len(finetune_adata.obs[\"Celltype\"].unique())} types')\n",
    "logger.info(f\"Test data cell type: {test_adata.obs['Celltype'].unique()} -- {len(test_adata.obs['Celltype'].unique())} types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_199495/1515216355.py:9: FutureWarning: Use anndata.concat instead of AnnData.concatenate, AnnData.concatenate is deprecated and will be removed in the future. See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  adata = finetune_adata.concatenate(test_adata, batch_key=\"str_batch\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Removed gene labels: ['RGS5']\n"
     ]
    }
   ],
   "source": [
    "finetune_adata.obs[\"celltype\"] = finetune_adata.obs[\"Celltype\"].astype(\"category\")\n",
    "finetune_adata.obs[\"batch_id\"] = finetune_adata.obs['str_batch'] = \"0\"\n",
    "finetune_adata.var[\"gene_name\"] = finetune_adata.var[\"Gene Symbol\"].tolist()\n",
    "test_adata.obs[\"celltype\"] = test_adata.obs[\"Celltype\"].astype(\"category\")\n",
    "test_adata.obs[\"batch_id\"] = test_adata.obs['str_batch'] = \"1\"\n",
    "test_adata.var[\"gene_name\"] = test_adata.var[\"Gene Symbol\"].tolist()\n",
    "\n",
    "adata_test_temp = test_adata.copy()\n",
    "adata = finetune_adata.concatenate(test_adata, batch_key=\"str_batch\")\n",
    "\n",
    "# make the batch category column\n",
    "batch_id_labels = adata.obs[\"str_batch\"].astype(\"category\").cat.codes.values\n",
    "adata.obs[\"batch_id\"] = batch_id_labels\n",
    "celltype_id_labels = adata.obs[\"celltype\"].astype(\"category\").cat.codes.values\n",
    "celltypes = adata.obs[\"celltype\"].unique()\n",
    "num_types = len(np.unique(celltype_id_labels))\n",
    "finetune_config.set_model_param('supervised_out_feature', num_types)\n",
    "\n",
    "adata.obs[\"celltype_id\"] = celltype_id_labels\n",
    "adata.var[\"gene_name\"] = adata.var.index.tolist()\n",
    "# get cell type id to cell type name mapping\n",
    "id2type = dict(enumerate(adata.obs[\"celltype\"].astype(\"category\").cat.categories))\n",
    "\n",
    "adata, removed_gene_labels = check_vocab(adata, data_params['vocab_path'])\n",
    "logger.info(f\"Removed gene labels: {removed_gene_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Filtering cells by counts ...\n",
      "Tabula - INFO - Normalizing total counts ...\n",
      "Tabula - INFO - Binning data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/first19T/linjh/anaconda3/envs/sctabular/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:138: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['n_counts'] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Filtering cells by counts ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/first19T/linjh/anaconda3/envs/sctabular/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:138: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['n_counts'] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Normalizing total counts ...\n",
      "Tabula - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=False,  # step 1\n",
    "    filter_cell_by_counts=False,  # step 2\n",
    "    normalize_total=1e4,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=data_params['data_is_raw'],  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=data_params['n_hvg'],  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_params['data_is_raw'] else \"cell_ranger\",\n",
    "    binning=data_params['n_bins'],  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "# split train and test data\n",
    "adata_test = adata[adata.obs[\"str_batch\"] == \"1\"]\n",
    "adata_finetune = adata[adata.obs[\"str_batch\"] == \"0\"]\n",
    "preprocessor(adata_test, batch_key=None)\n",
    "preprocessor(adata_finetune, batch_key=None)\n",
    "adata_test_raw = adata_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Train data size: 9540\n",
      "Tabula - INFO - Valid data size: 1060\n",
      "Tabula - INFO - Train data loader size: 298\n",
      "Tabula - INFO - Valid data loader size: 33\n",
      "Tabula - INFO - Number of cell type in training data: 13\n"
     ]
    }
   ],
   "source": [
    "# get batch labels\n",
    "batch_id_labels = adata_finetune.obs[\"str_batch\"].astype(\"category\").cat.codes.values\n",
    "adata_finetune.obs[\"batch_id\"] = batch_id_labels\n",
    "# get cell type labels mapped by id2type\n",
    "celltype_str_list = adata_finetune.obs[\"celltype\"].tolist()\n",
    "# use id2type to convert cell type string to cell type id\n",
    "celltype_id_labels = [list(id2type.keys())[list(id2type.values()).index(celltype_str)] for celltype_str in celltype_str_list]\n",
    "\n",
    "# get expression table\n",
    "binned_expression_table = adata_finetune.layers[\"X_binned\"]\n",
    "\n",
    "# get gene ids\n",
    "adata_finetune.var[\"gene_name\"] = adata_finetune.var[\"gene_name\"].tolist()\n",
    "gene_ids = adata_finetune.var[\"gene_name\"].tolist()\n",
    "\n",
    "dataset = CellAnnotationDataset(expression_table=binned_expression_table,\n",
    "                                masked_expression_table=None,\n",
    "                                gene_ids=gene_ids,\n",
    "                                labels=celltype_id_labels,\n",
    "                                batch_strings=batch_id_labels,\n",
    "                                x_umap=None,\n",
    "                                in_feature=finetune_config.get_model_param('in_feature'),\n",
    "                                vocab_file=data_params['vocab_path'])\n",
    "train_indices, valid_indices = train_test_split(range(len(dataset)), test_size=0.1, shuffle=True)\n",
    "logger.info(f\"Train data size: {len(train_indices)}\")\n",
    "logger.info(f\"Valid data size: {len(valid_indices)}\")\n",
    "\n",
    "# split train and valid dataset\n",
    "train_set = torch.utils.data.Subset(dataset, train_indices)\n",
    "valid_set = torch.utils.data.Subset(dataset, valid_indices)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=data_params['batch_size'], \n",
    "                          shuffle=True, num_workers=data_params['n_workers'], drop_last=True)\n",
    "valid_loader = DataLoader(dataset=valid_set, batch_size=data_params['batch_size'], \n",
    "                          shuffle=False,num_workers=data_params['n_workers'], drop_last=True)\n",
    "logger.info(f\"Train data loader size: {len(train_loader)}\")\n",
    "logger.info(f\"Valid data loader size: {len(valid_loader)}\")\n",
    "logger.info(f'Number of cell type in training data: {len(np.unique(celltype_id_labels))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Test data removed gene number: 0 from vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_199495/26445261.py:7: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata_test_raw.obs[\"label\"] = label_list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabula - INFO - Test data size: 4218\n",
      "Tabula - INFO - Test data loader size: 132\n"
     ]
    }
   ],
   "source": [
    "# set eval dataset\n",
    "adata_test_raw, removed_gene_labels = check_vocab(adata_test_raw, data_params['vocab_path'])\n",
    "logger.info(f\"Test data removed gene number: {len(removed_gene_labels)} from vocab\")\n",
    "    \n",
    "label_list = adata_test_raw.obs[\"celltype\"].tolist()\n",
    "label_list = [list(id2type.keys())[list(id2type.values()).index(celltype_str)] for celltype_str in label_list]\n",
    "adata_test_raw.obs[\"label\"] = label_list\n",
    "    \n",
    "eval_dataset = CellAnnotationDataset(\n",
    "    expression_table=adata_test_raw.layers[\"X_binned\"],\n",
    "    masked_expression_table=None,\n",
    "    gene_ids=adata_test_raw.var[\"gene_name\"].tolist(),\n",
    "    labels=adata_test_raw.obs[\"label\"],\n",
    "    batch_strings=adata_test_raw.obs[\"batch_id\"].astype(\"category\").cat.codes.values,\n",
    "    x_umap=adata_test_temp.obsm[\"X_umap\"],\n",
    "    in_feature=finetune_config.get_model_param('in_feature'),\n",
    "    vocab_file=data_params['vocab_path'])\n",
    "test_loader = DataLoader(\n",
    "    dataset=eval_dataset, \n",
    "    batch_size=data_params['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=data_params['n_workers'], \n",
    "    drop_last=False)\n",
    "logger.info(f\"Test data size: {len(eval_dataset)}\")\n",
    "logger.info(f\"Test data loader size: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained Tabula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['device'] != 'cpu' and not torch.cuda.is_available():\n",
    "    logger.error(f'Cuda is not available, change device to cpu')\n",
    "    params['device'] = 'cpu'\n",
    "tabula_pl_model = get_pretrained_model(\n",
    "    finetune_config=finetune_config,\n",
    "    model_path=params['model_path'],\n",
    "    device=params['device']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_trainer = CellTypeAnnotation(\n",
    "    config=finetune_config,\n",
    "    tabula_model=tabula_pl_model,\n",
    "    wandb_logger=wandb_logger,\n",
    "    device=params['device'],\n",
    "    batch_size=data_params['batch_size'],\n",
    "    id2celltype=id2type,\n",
    "    dataloaders={'train_loader': train_loader, \n",
    "                 'val_loader': valid_loader,\n",
    "                 'test_loader': test_loader}\n",
    "    )\n",
    "\n",
    "annotation_trainer.finetune()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sctabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
